name: Run Decoder

on:
  push:
    branches: [main, test/visualizer-refactor]
  pull_request:
    branches: [main, test/visualizer-refactor]
  workflow_dispatch:

jobs:
  run-decoder:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4   # ← updated to latest version

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3   # ← newer version

      - name: Cache Docker layers
        uses: actions/cache@v4   # ← updated
        with:
          path: /tmp/.buildx-cache
          key: ${{ runner.os }}-buildx-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-buildx-

      - name: Build Docker image
        uses: docker/build-push-action@v6   # ← latest major version
        with:
          context: .
          load: true
          tags: decoder-image:latest
          cache-from: type=local,src=/tmp/.buildx-cache
          cache-to: type=local,dest=/tmp/.buildx-cache-new,mode=max

      - name: Move updated cache
        run: |
          rm -rf /tmp/.buildx-cache
          mv /tmp/.buildx-cache-new /tmp/.buildx-cache || true

      # Create output folders **before** running container
      - name: Prepare output directories
        run: |
          mkdir -p plots/cluster
          mkdir -p results
          chmod -R 777 plots results
          ls -ld plots results

      - name: Show CPU information
        run: |
          echo "Total CPUs : $(nproc)"
          echo "Memory     : $(free -h)"
          echo "Disk space : $(df -h .)"

      - name: Run decoder (beam search)
        run: |
          set -x   # ← show commands → easier debugging

          docker run --rm \
            -v "${{ github.workspace }}:/app" \
            -e PYTHONUNBUFFERED=1 \
            --cpus=4 \          # optional: limit to 4 cores
            decoder-image:latest \
            bash -c "
              set -e -x

              cd /app

              echo 'Starting decoder (beam search)...'
              python -m subgraph_mining.decoder \
                --dataset=metta.pkl \
                --search_strategy=beam \
                --beam_width=5 \
                --n_trials=200 \
                --node_anchored \
                --out_path=/app/results/patterns-beam.pkl

              echo '────────────────────────────────────────'
              echo 'Sanity checking beam output...'

              python -c '
import os, pickle, sys
path = \"/app/results/patterns-beam.pkl\"
if not os.path.exists(path):
    print(f\"ERROR: File not found → {path}\")
    print(\"Directory content:\")
    os.system(\"ls -la /app/results\")
    sys.exit(1)

with open(path, \"rb\") as f:
    patterns = pickle.load(f)

if not patterns:
    print(\"ERROR: patterns list is empty!\")
    sys.exit(2)

print(f\"OK: Beam search produced {len(patterns)} patterns\")
              '

              echo '────────────────────────────────────────'
              echo 'Output directories content:'
              ls -la /app/results || true
              ls -la /app/plots   || true
            "

      - name: List generated files (debug)
        run: |
          echo "Workspace root:"
          ls -la .
          echo "Results:"
          ls -R results || echo "(empty or missing)"
          echo "Plots:"
          ls -R plots   || echo "(empty or missing)"

      - name: Upload artifacts (plots & results)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: decoder-output
          path: |
            plots/
            results/
          retention-days: 7
          if-no-files-found: warn

      - name: Upload logs & errors (if any)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: decoder-logs
          path: |
            **/*.log
            **/*.err
            **/*.txt
          if-no-files-found: ignore